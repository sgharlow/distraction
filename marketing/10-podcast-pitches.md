# Item 10: Podcast Pitch Emails

---

## Pitch 1: On the Media (WNYC)

**Submit:** https://www.wnycstudios.org/podcasts/otm/contact
**Why:** Leading media criticism podcast — exact audience

**Subject:** Pitch: Open-source tool that scores political events on damage vs. distraction axes

Hi On the Media team,

I built The Distraction Index — a civic intelligence tool that scores every political event on two independent axes: constitutional damage and media distraction. After 59 weeks, we've identified 210+ "smokescreen" instances where high-distraction events coincided with undercovered institutional damage.

The twist: every scoring formula, weight, and AI prompt is published publicly. It's an experiment in radical transparency for automated political analysis.

I'd love to discuss:
- Why scoring events (not sources) reveals patterns bias charts can't
- What 59 weeks of dual-axis data tells us about attention and democracy
- The ethics and challenges of AI-powered political scoring
- Whether algorithmic transparency can rebuild trust in media analysis

**Bio:** [Your 2-3 sentence bio]
**Website:** https://distractionindex.org
**Methodology:** https://distractionindex.org/methodology

Best,
[Your Name]

---

## Pitch 2: The Weeds (Vox / Matthew Yglesias)

**Submit via:** Social media DM or Vox tips
**Why:** Policy-focused, methodology-curious audience

**Subject:** Pitch: What dual-axis scoring of 1,500+ political events reveals about media attention

Hi,

I'm the creator of The Distraction Index, a project that scores political events on both institutional damage and media distraction independently. The insight: these axes are surprisingly uncorrelated — the events that cause the most democratic harm often aren't the ones getting the most coverage.

After 59 weeks and 1,500+ scored events, some patterns have emerged:
- Certain damage categories (e.g., judicial independence) are systematically undercovered
- High-intentionality distractions show distinct temporal patterns
- The "attention budget" gap between damage and coverage is widening

Would this be a fit for a segment on media incentives and democratic health?

**Website:** https://distractionindex.org

---

## Pitch 3: Civic Tech / Data Journalism Podcasts

**Targets:**
- **Data Stories** — https://datastori.es/contact/
- **Partially Derivative** — data science podcast
- **GovFresh** — civic tech podcast
- **The Civic Pulse** — civic engagement

**Generic pitch (customize per show):**

**Subject:** Pitch: AI-powered civic intelligence — dual-axis scoring of political events

Hi [Host Name],

I built an open-source civic tech platform called The Distraction Index that uses AI to score political events on two axes: constitutional damage and media distraction.

The technical stack: Claude Haiku clusters articles into events, Claude Sonnet scores them using structured prompts, and the results are published as immutable weekly snapshots.

After 59 weeks: 1,500+ events, 210+ smokescreen pairs, 220 tests, fully open source.

I'd love to discuss:
- The engineering challenges of building a transparent AI scoring pipeline
- Why immutable weekly snapshots matter for civic trust
- How the dual-axis approach differs from media bias charts
- The open-source civic tech community and where it's heading

**Website:** https://distractionindex.org
**Open source:** https://github.com/sgharlow/distraction

---

## Pitch 4: Tech/AI Podcasts

**Targets:**
- **Practical AI** — AI applications podcast
- **AI in Business** — enterprise AI
- **Lex Fridman** (long shot, high reach)
- **Hard Fork** (NYT) — tech culture

**Subject:** Pitch: Using Claude API for transparent civic intelligence — lessons from 59 weeks of automated political scoring

Hi [Host Name],

I've been running an automated AI pipeline for 59 weeks that ingests news articles, clusters them into events, and scores each event on two independent axes using Claude's API.

What I've learned about building transparent AI systems:
- Publishing your prompts publicly is terrifying and essential
- Immutability prevents silent model drift from corrupting historical analysis
- The two-axis approach reveals patterns that single-dimension models miss
- Cost optimization: ~$30/month for a production AI pipeline (Haiku for clustering, Sonnet only for scoring)

The Distraction Index is fully open source with 220 tests. Happy to go deep on the technical architecture.

**Website:** https://distractionindex.org

---

## Pitch 5: Political Podcasts

**Targets:**
- **Pod Save America** — large progressive audience
- **The Bulwark** — center-right, anti-populist
- **FiveThirtyEight Politics** — data-driven analysis
- **The NPR Politics Podcast**

**Subject:** 210+ times media spectacle masked real democratic damage — data from 59 weeks of scoring

Hi [Producer/Host],

Quick pitch: I built a tool that algorithmically identifies when political distractions coincide with undercovered institutional damage. After 59 weeks, we've found 210+ such "smokescreen" pairings.

The interesting finding: some categories of democratic damage (judicial independence, environmental policy) are systematically undercovered regardless of which distraction is dominating the news cycle.

The tool scores events, not media outlets — so this isn't about "bias" in the traditional sense. It's about attention economics and what gets coverage vs. what matters.

All methodology is transparent: https://distractionindex.org/methodology

Happy to discuss as a segment on media incentives and democratic accountability.

Best,
[Your Name]

---

## Submission Tracking Template

| Podcast | Contact Method | Date Sent | Follow-up | Response |
|---------|---------------|-----------|-----------|----------|
| On the Media | Web form | | | |
| The Weeds | Social DM | | | |
| Data Stories | Email | | | |
| Practical AI | Email | | | |
| Pod Save America | Web form | | | |
| Hard Fork | NYT tips | | | |
| NPR Politics | Web form | | | |
